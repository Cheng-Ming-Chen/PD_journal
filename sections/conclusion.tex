Wireless spectrum monitoring and signal classification over frequency, time and space dimensions is still an active research problem. In this paper we proposed a new \ac{lstm} based model which can classify signals with time domain amplitude and phase as input. \ac{soa} results on high \ac{snr}s (0 to 20dB) is achieved without using complex \ac{cnn}-\ac{lstm} models as mentioned in \cite{baseline}. Being a recurrent model we showed that the model can handle variable length inputs thus can capture sample rate variations effectively.



 %However, as there are various modulation schemes that exhibit same power spectral characteristics, which is well known in the research community, a detailed study is conducted on the complex \ac{iq} model variants. To also be able to handle such complex signals, a new \ac{lstm} based modulation classifier is proposed. 

%\sofie{I understand why you put magnitude FFT first: it is compliant with Electrosense. The full IQ study motivation is not that well introduced. Would it be useful to have also average phase FFT information? And compare then time versus frequency, phase verus amplitude, averaging versus full? Nowit is all a bit confusing...}

Though neural networks are good at function approximation, our experiments emphasize the fact that \emph{data preprocessing} and \emph{proper representation} are equally important. This claim is substantiated from our experiments with the \ac{lstm} model where the model gave poor results when fed with time domain \ac{iq} samples while it gave accuracies close to 90\% for high \ac{snr}s when provided with time domain amplitude and phase information. %\sofie{What about frequency domaing amplitude and phase?} 
 As shown by various \ac{soa} models in speech and image domains, performance improvements are seen with increasing layer depth which saturates after a few levels. In addition, we showed that basic technology classification is achievable by only using averaged magnitude \ac{fft} information over a distributed set of sensors complying with the uplink bandwidth resource constraints. Furthermore, experiments showed that quantized \ac{lstm} models can achieve good classification results thus reducing the processing power requirements at the cost of 10\% accuracy loss. This allows the deployment of these models on low cost sensors networks such as Electrosense enabling a wide area deployment. It is also remarkable that these deep learning models can classify signals with a fewer number of samples when compared to the expert feature variants, such as cyclic frequency estimators, enabling faster classification. Furthermore, deep learning allows for incremental learning, thus it would not be required to retrain the entire network from scratch for the new wireless non-idealities like antenna patterns and sensitivity. In addition, dedicated hardware is gaining popularity to reduce the deep learning model's energy and memory footprints which demands quantized versions of the models.

Although the \ac{lstm} models perform very well at high \ac{snr} conditions, CNN models seems to provide an additional 5-10\% accuracy on the low \ac{snr} conditions (SNRs below -2dB) as shown in \cite{baseline}. Even though we are not able to replicate the results in \cite{baseline} (%might be 
because of hyperparameter tuning), it is reasonable to conclude that the learned filters in CNN for a fixed sample rate might give performance improvements for low SNR values. Furthermore, all the implemented code for the proposed models are made publicly available for reproducing and verifying the results presented in this paper and for supporting future research.

Low \ac{snr} performance of these \ac{soa} deep learning models could be further improved with the help of efficient blind denoising models. Models which can perform automated channel equalization and compensate receiver imperfections such as frequency offset can further improve the classification performance. The current radio deep learning models make use of layers which basically applies non-linearity after simple multiply-accumulate-add operations while it is well established in the research community that cyclic cumulants, which are generated by time-shifted multiplication and averaging of the input itself, performs well in the expert feature space. Deep learning models which can extract features similar to cyclic cumulants might improve the performance metrics.

The analysis would not be complete without emphasizing the limitations of the \ac{soa} deep learning models. First, the current complex models are tested on a dataset with normalized bandwidth parameters. Real life transmitted signals generally have varying symbol rates and bandwidths. Even though the variable length \ac{lstm} model is shown to be capable of adapting to these scenarios, further analysis is required to validate the claim. %In addition, new datasets with more difficult modulation schemes like frequency-hopping and direct-sequence spread spectrum should be also tested. 
In future, models that can handle all possible spread spectrum modulations should be also tested. Second, the generalization capabilities of these models should be further investigated, in terms of performance of these models in unknown channel conditions and modulation parameters. Finally, most of the successful \ac{soa} models are supervised models which requires labeled training data. Labeling is a very tedious task which projects the importance of semi-supervised models for classification tasks. Published studies \cite{mlresource} on semi-supervised machine learning models for cellular network resource management validates the need for more semi-supervised models, which is also an active direction for future research. We believe deep learning models adapted to radio domain can help in understanding, analyzing and decision making in future complex radio environments.